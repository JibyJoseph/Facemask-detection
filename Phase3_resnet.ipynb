{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_LKQvsvuZADS",
    "outputId": "527ee63b-371d-4b60-f2bb-2e35cfc65939"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "Zlc_Ovq2k5vf"
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from imutils import paths\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RfT9eMzbv6xN"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Npd-3hH3mhyn",
    "outputId": "fb892293-d991-4f66-f589-90fec5f9580e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GPU at: /device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "device_name = tf.test.gpu_device_name()\n",
    "if device_name != '/device:GPU:0':\n",
    "  raise SystemError('GPU device not found')\n",
    "print('Found GPU at: {}'.format(device_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eqDzmsLtmtaf",
    "outputId": "8e3a1b55-a19a-4f8c-b83f-eabd30b1a0a6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jun  9 05:22:18 2021       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 465.27       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   60C    P8    10W /  70W |      0MiB / 15109MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|  No running processes found                                                 |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_JOo7wxlc-y",
    "outputId": "5d7e5fc3-7878-479b-96eb-2cae3f86719d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] loading images...\n"
     ]
    }
   ],
   "source": [
    "# initialize the initial learning rate, number of epochs to train for,\n",
    "# and batch size\n",
    "INIT_LR = 1e-4\n",
    "EPOCHS = 20\n",
    "BS = 32\n",
    "\n",
    "DIRECTORY = \"/content/drive/My Drive/TestImages/dataset\"\n",
    "CATEGORIES = [\"with_mask\", \"without_mask\",\"improper_mask\"]\n",
    "\n",
    "# grab the list of images in our dataset directory, then initialize\n",
    "# the list of data (i.e., images) and class images\n",
    "print(\"[INFO] loading images...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ACfA7FuHl3jR",
    "outputId": "c23de73e-abe1-4495-e13b-8f48827b0f51"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 53/1903 [00:00<00:11, 156.56it/s]/usr/local/lib/python3.7/dist-packages/PIL/Image.py:960: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
      "  \"Palette images with Transparency expressed in bytes should be \"\n",
      "100%|██████████| 1903/1903 [00:10<00:00, 178.88it/s]\n",
      "100%|██████████| 1918/1918 [00:05<00:00, 378.87it/s]\n",
      "100%|██████████| 867/867 [00:14<00:00, 59.68it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "dataRaw = []\n",
    "labels = []\n",
    "\n",
    "for category in (CATEGORIES):\n",
    "    path = os.path.join(DIRECTORY, category)\n",
    "    for img in tqdm(os.listdir(path)):\n",
    "    \timg_path = os.path.join(path, img)\n",
    "    \timage = load_img(img_path, target_size=(224, 224))\n",
    "    \timage = img_to_array(image)\n",
    "    \t#image = preprocess_input(image)\n",
    "\n",
    "    \tdataRaw.append(image)\n",
    "    \tlabels.append(category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "sS88oQR2xdSq"
   },
   "outputs": [],
   "source": [
    "data = []\n",
    "for img in dataRaw:\n",
    "  data.append(preprocess_input(img))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Y51R7u9cm37F"
   },
   "outputs": [],
   "source": [
    "lb = LabelBinarizer()\n",
    "lb.fit(CATEGORIES)\n",
    "labels1 = lb.transform(labels)\n",
    "#labels2 = to_categorical(labels1)\n",
    "\n",
    "data = np.array(data, dtype=\"float32\")\n",
    "labels = np.array(labels)\n",
    "\n",
    "(trainX, testX, trainY, testY) = train_test_split(data, labels1,\n",
    "\ttest_size=0.20, stratify=labels1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "V-aSB-Ftl7U_",
    "outputId": "58e6e080-9770-45ca-851a-9107d4632009"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1]\n",
      "without_mask\n",
      "4688\n"
     ]
    }
   ],
   "source": [
    "g=2000\n",
    "print(labels1[g])\n",
    "print(labels[g])\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Zw_RExDam9Di"
   },
   "outputs": [],
   "source": [
    "# construct the training image generator for data augmentation\n",
    "aug = ImageDataGenerator(\n",
    "\trotation_range=20,\n",
    "\tzoom_range=0.15,\n",
    "\twidth_shift_range=0.2,\n",
    "\theight_shift_range=0.2,\n",
    "\tshear_range=0.15,\n",
    "\thorizontal_flip=True,\n",
    "\tfill_mode=\"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YRVmLW7cnCDO",
    "outputId": "1e793e73-d1c8-4326-e749-4dd65aef833d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] compiling model...\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 230, 230, 3)  0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 112, 112, 64) 9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv1_bn (BatchNormalization)   (None, 112, 112, 64) 256         conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv1_relu (Activation)         (None, 112, 112, 64) 0           conv1_bn[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 114, 114, 64) 0           conv1_relu[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 56, 56, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 56, 56, 64)   4160        pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 56, 56, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 56, 56, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 56, 56, 256)  16640       pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_add (Add)          (None, 56, 56, 256)  0           conv2_block1_0_bn[0][0]          \n",
      "                                                                 conv2_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Activation)   (None, 56, 56, 256)  0           conv2_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 56, 56, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 56, 56, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_add (Add)          (None, 56, 56, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Activation)   (None, 56, 56, 256)  0           conv2_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 56, 56, 64)   16448       conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 56, 56, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 56, 56, 64)   36928       conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 56, 56, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 56, 56, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 56, 56, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_bn (BatchNormali (None, 56, 56, 256)  1024        conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_add (Add)          (None, 56, 56, 256)  0           conv2_block2_out[0][0]           \n",
      "                                                                 conv2_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Activation)   (None, 56, 56, 256)  0           conv2_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 28, 28, 128)  32896       conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 28, 28, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 28, 28, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 28, 28, 512)  131584      conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_add (Add)          (None, 28, 28, 512)  0           conv3_block1_0_bn[0][0]          \n",
      "                                                                 conv3_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Activation)   (None, 28, 28, 512)  0           conv3_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 28, 28, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 28, 28, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_add (Add)          (None, 28, 28, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Activation)   (None, 28, 28, 512)  0           conv3_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 28, 28, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 28, 28, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_add (Add)          (None, 28, 28, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Activation)   (None, 28, 28, 512)  0           conv3_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 28, 28, 128)  65664       conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 28, 28, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 28, 28, 128)  147584      conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 28, 28, 128)  512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 28, 28, 128)  0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 28, 28, 512)  66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_bn (BatchNormali (None, 28, 28, 512)  2048        conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_add (Add)          (None, 28, 28, 512)  0           conv3_block3_out[0][0]           \n",
      "                                                                 conv3_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Activation)   (None, 28, 28, 512)  0           conv3_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 14, 14, 256)  131328      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 14, 14, 256)  0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 14, 14, 256)  0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 14, 14, 1024) 525312      conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_0_bn[0][0]          \n",
      "                                                                 conv4_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Activation)   (None, 14, 14, 1024) 0           conv4_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 14, 14, 256)  0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 14, 14, 256)  0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_add (Add)          (None, 14, 14, 1024) 0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Activation)   (None, 14, 14, 1024) 0           conv4_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 14, 14, 256)  0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 14, 14, 256)  0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_add (Add)          (None, 14, 14, 1024) 0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Activation)   (None, 14, 14, 1024) 0           conv4_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 14, 14, 256)  0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 14, 14, 256)  0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_add (Add)          (None, 14, 14, 1024) 0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Activation)   (None, 14, 14, 1024) 0           conv4_block4_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 14, 14, 256)  0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 14, 14, 256)  0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_add (Add)          (None, 14, 14, 1024) 0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Activation)   (None, 14, 14, 1024) 0           conv4_block5_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 14, 14, 256)  262400      conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 14, 14, 256)  0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 14, 14, 256)  590080      conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 14, 14, 256)  1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 14, 14, 256)  0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 14, 14, 1024) 263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_bn (BatchNormali (None, 14, 14, 1024) 4096        conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_add (Add)          (None, 14, 14, 1024) 0           conv4_block5_out[0][0]           \n",
      "                                                                 conv4_block6_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Activation)   (None, 14, 14, 1024) 0           conv4_block6_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 7, 7, 512)    524800      conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 7, 7, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 7, 7, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 7, 7, 2048)   2099200     conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_0_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_0_bn[0][0]          \n",
      "                                                                 conv5_block1_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Activation)   (None, 7, 7, 2048)   0           conv5_block1_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 7, 7, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 7, 7, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_add (Add)          (None, 7, 7, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Activation)   (None, 7, 7, 2048)   0           conv5_block2_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 7, 7, 512)    1049088     conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 7, 7, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 7, 7, 512)    2359808     conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 7, 7, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 7, 7, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 7, 7, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_bn (BatchNormali (None, 7, 7, 2048)   8192        conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_add (Add)          (None, 7, 7, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Activation)   (None, 7, 7, 2048)   0           conv5_block3_add[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d (AveragePooli (None, 1, 1, 2048)   0           conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 2048)         0           average_pooling2d[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          262272      flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 3)            387         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 23,850,371\n",
      "Trainable params: 262,659\n",
      "Non-trainable params: 23,587,712\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/optimizer_v2/optimizer_v2.py:375: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
     ]
    }
   ],
   "source": [
    "baseModel = ResNet50(weights=\"imagenet\", include_top=False,input_tensor=Input(shape=(224, 224, 3)))\n",
    "\n",
    "\n",
    "headModel = baseModel.output\n",
    "headModel = AveragePooling2D(pool_size=(7, 7))(headModel)\n",
    "headModel = Flatten(name=\"flatten\")(headModel)\n",
    "headModel = Dense(128, activation=\"relu\")(headModel)\n",
    "#headModel = Dropout(0.5)(headModel)\n",
    "headModel = Dense(3, activation=\"softmax\")(headModel)\n",
    "\n",
    "model = Model(inputs=baseModel.input, outputs=headModel)\n",
    "\n",
    "for layer in baseModel.layers:\n",
    "  layer.trainable = False\n",
    "\n",
    "print(\"[INFO] compiling model...\")\n",
    "opt = Adam(lr=INIT_LR, decay=INIT_LR / EPOCHS)\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=opt,\n",
    "\tmetrics=[\"accuracy\"])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a4xblc8snStu",
    "outputId": "f630bdd1-a295-4941-c264-4fe6aa9ebb01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] training head...\n",
      "Epoch 1/20\n",
      "117/117 [==============================] - 75s 356ms/step - loss: 0.2415 - accuracy: 0.8903 - val_loss: 0.0688 - val_accuracy: 0.9872\n",
      "Epoch 2/20\n",
      "117/117 [==============================] - 40s 339ms/step - loss: 0.0545 - accuracy: 0.9914 - val_loss: 0.0352 - val_accuracy: 0.9893\n",
      "Epoch 3/20\n",
      "117/117 [==============================] - 40s 341ms/step - loss: 0.0327 - accuracy: 0.9938 - val_loss: 0.0240 - val_accuracy: 0.9936\n",
      "Epoch 4/20\n",
      "117/117 [==============================] - 40s 340ms/step - loss: 0.0241 - accuracy: 0.9952 - val_loss: 0.0195 - val_accuracy: 0.9936\n",
      "Epoch 5/20\n",
      "117/117 [==============================] - 40s 338ms/step - loss: 0.0209 - accuracy: 0.9944 - val_loss: 0.0172 - val_accuracy: 0.9936\n",
      "Epoch 6/20\n",
      "117/117 [==============================] - 40s 339ms/step - loss: 0.0172 - accuracy: 0.9962 - val_loss: 0.0150 - val_accuracy: 0.9947\n",
      "Epoch 7/20\n",
      "117/117 [==============================] - 40s 341ms/step - loss: 0.0151 - accuracy: 0.9957 - val_loss: 0.0171 - val_accuracy: 0.9936\n",
      "Epoch 8/20\n",
      "117/117 [==============================] - 40s 339ms/step - loss: 0.0130 - accuracy: 0.9970 - val_loss: 0.0128 - val_accuracy: 0.9947\n",
      "Epoch 9/20\n",
      "117/117 [==============================] - 40s 339ms/step - loss: 0.0116 - accuracy: 0.9973 - val_loss: 0.0126 - val_accuracy: 0.9947\n",
      "Epoch 10/20\n",
      "117/117 [==============================] - 39s 337ms/step - loss: 0.0106 - accuracy: 0.9973 - val_loss: 0.0126 - val_accuracy: 0.9947\n",
      "Epoch 11/20\n",
      "117/117 [==============================] - 39s 335ms/step - loss: 0.0091 - accuracy: 0.9978 - val_loss: 0.0136 - val_accuracy: 0.9947\n",
      "Epoch 12/20\n",
      "117/117 [==============================] - 39s 337ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.0138 - val_accuracy: 0.9947\n",
      "Epoch 13/20\n",
      "117/117 [==============================] - 39s 337ms/step - loss: 0.0075 - accuracy: 0.9981 - val_loss: 0.0121 - val_accuracy: 0.9947\n",
      "Epoch 14/20\n",
      "117/117 [==============================] - 39s 336ms/step - loss: 0.0080 - accuracy: 0.9984 - val_loss: 0.0112 - val_accuracy: 0.9947\n",
      "Epoch 15/20\n",
      "117/117 [==============================] - 39s 335ms/step - loss: 0.0077 - accuracy: 0.9984 - val_loss: 0.0112 - val_accuracy: 0.9947\n",
      "Epoch 16/20\n",
      "117/117 [==============================] - 39s 334ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0133 - val_accuracy: 0.9947\n",
      "Epoch 17/20\n",
      "117/117 [==============================] - 39s 334ms/step - loss: 0.0051 - accuracy: 0.9987 - val_loss: 0.0112 - val_accuracy: 0.9957\n",
      "Epoch 18/20\n",
      "117/117 [==============================] - 39s 337ms/step - loss: 0.0059 - accuracy: 0.9976 - val_loss: 0.0109 - val_accuracy: 0.9968\n",
      "Epoch 19/20\n",
      "117/117 [==============================] - 39s 333ms/step - loss: 0.0059 - accuracy: 0.9984 - val_loss: 0.0110 - val_accuracy: 0.9979\n",
      "Epoch 20/20\n",
      "117/117 [==============================] - 39s 334ms/step - loss: 0.0048 - accuracy: 0.9992 - val_loss: 0.0109 - val_accuracy: 0.9968\n"
     ]
    }
   ],
   "source": [
    "# train the head of the network\n",
    "print(\"[INFO] training head...\")\n",
    "H = model.fit(\n",
    "\taug.flow(trainX, trainY, batch_size=BS),\n",
    "\tsteps_per_epoch=len(trainX) // BS,\n",
    "\tvalidation_data=(testX, testY),\n",
    "\tvalidation_steps=len(testX) // BS,\n",
    "\tepochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JTb-k00l3PS6",
    "outputId": "f858df89-a34b-4d0a-e64e-ff97f3b53668"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] evaluating network...\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "improper_mask       0.99      0.99      0.99       173\n",
      "    with_mask       1.00      1.00      1.00       381\n",
      " without_mask       1.00      1.00      1.00       384\n",
      "\n",
      "     accuracy                           1.00       938\n",
      "    macro avg       1.00      1.00      1.00       938\n",
      " weighted avg       1.00      1.00      1.00       938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make predictions on the testing set\n",
    "print(\"[INFO] evaluating network...\")\n",
    "predIdxs = model.predict(testX, batch_size=BS)\n",
    "\n",
    "# for each image in the testing set we need to find the index of the\n",
    "# label with corresponding largest predicted probability\n",
    "predIdxs = np.argmax(predIdxs, axis=1)\n",
    "\n",
    "# show a nicely formatted classification report\n",
    "print(classification_report(testY.argmax(axis=1), predIdxs,\n",
    "\ttarget_names=lb.classes_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TCbvFBnD3QIZ",
    "outputId": "0d1e6801-1681-4b17-db49-99b32fc8b98c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] saving mask detector model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n"
     ]
    }
   ],
   "source": [
    "# serialize the model to disk\n",
    "print(\"[INFO] saving mask detector model...\")\n",
    "model.save(\"/content/drive/MyDrive/TestImages/mask_detector_Resnet50_20.model\", save_format=\"h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 299
    },
    "id": "CdQXS3Sk3Tju",
    "outputId": "381c957f-81ea-4247-db35-b7d69a5eafd2"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the training loss and accuracy\n",
    "N = EPOCHS\n",
    "plt.style.use(\"ggplot\")\n",
    "plt.figure()\n",
    "plt.plot(np.arange(0, N), H.history[\"loss\"], label=\"train_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_loss\"], label=\"val_loss\")\n",
    "plt.plot(np.arange(0, N), H.history[\"accuracy\"], label=\"train_acc\")\n",
    "plt.plot(np.arange(0, N), H.history[\"val_accuracy\"], label=\"val_acc\")\n",
    "plt.title(\"Training Loss and Accuracy\")\n",
    "plt.xlabel(\"Epoch #\")\n",
    "plt.ylabel(\"Loss/Accuracy\")\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.savefig(\"plot.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5jg7eRAX3WOP"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Phase3_resnet.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
